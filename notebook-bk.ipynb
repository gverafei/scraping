{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gverafei/scraping/blob/main/scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3flX_YcJTu05"
      },
      "source": [
        "# **Investigating how to scrape the web**\n",
        "April 2025\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initial method\n",
        "\n",
        "<center><img src=\"images/metodo.jpg\" style=\"margin:auto; width:90%\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Método simple como control\n",
        "\n",
        "<center><img src=\"images/metodo-slim1.jpg\" style=\"margin:auto; width:50%\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Método propuesto v1\n",
        "\n",
        "<center><img src=\"images/metodo-slim2.jpg\" style=\"margin:auto; width:50%\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Scraping WCAG\n",
        "\n",
        "Necesitamos guardar de alguna manera todo este conocimiento: https://www.w3.org/WAI/WCAG22/Understanding/\n",
        "\n",
        "O este conocimiento: https://www.w3.org/WAI/standards-guidelines/act/rules/\n",
        "\n",
        "<center><img src=\"images/metodo-craw.jpg\" style=\"margin:auto; width:50%\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctzFiDtTTu07"
      },
      "source": [
        "## Configure virtual environment\n",
        "\n",
        "Solo se ejecuta lo siguiente la primera vez. Pedirá seleccionar the kernel from the upper right corner. Choose this virtual environment we just created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1TQVRZzadcO",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "# !python3 -m venv .venv\n",
        "# !source .venv/bin/activate # Linux/Mac\n",
        "# !.\\venv\\Scripts\\activate # Windows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyXLvtvmadcP"
      },
      "source": [
        "Inicializa el repositorio en GitHub. Todo esto se hace desde la terminal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ztygE_IadcP",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "# !git init\n",
        "# !git remote add origin https://github.com/gverafei/scraping.git\n",
        "# !git pull origin main\n",
        "# git add .\n",
        "# git commit -m \"Initial commit\"\n",
        "# git push --set-upstream origin main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0PLl5W4adcP",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EspH7Z_nadcP"
      },
      "source": [
        "## Create the initial data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vo40HI4tnIBm"
      },
      "outputs": [],
      "source": [
        "test_sites = [\n",
        "    {\n",
        "        \"name\": \"Amazon\",\n",
        "        \"url\": \"https://www.amazon.com\"\n",
        "    },\n",
        "    # {\n",
        "    #     \"name\": \"UV\",\n",
        "    #     \"url\": \"https://www.uv.mx\"\n",
        "    # },\n",
        "    {\n",
        "        \"name\": \"W3C ACT Rules\",\n",
        "        \"url\": \"https://www.w3.org/WAI/standards-guidelines/act/rules/\"\n",
        "    },\n",
        "    # {\n",
        "    #     \"name\": \"W3C WCAG 2.2\",\n",
        "    #     \"url\": \"https://www.w3.org/WAI/WCAG22/Understanding/\"\n",
        "    # },\n",
        "    # {\n",
        "    #     \"name\": \"Chedrahui\",\n",
        "    #     \"url\": \"https://www.chedraui.com.mx\"\n",
        "    # },\n",
        "    # {\n",
        "    #     \"name\": \"FEI\",\n",
        "    #     \"url\": \"https://www.uv.mx/fei/\"\n",
        "    # },\n",
        "    {\n",
        "        \"name\": \"Sistemas FEI\",\n",
        "        \"url\": \"https://sistemasfei.uv.mx/inicio/\"\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkokkcBzadcQ"
      },
      "source": [
        "## Setup cost's calculations\n",
        "\n",
        "The idea is to compare side-by-side.\n",
        "\n",
        "We can calculate how much it'll cost by using OpenAI's `tiktoken` library from: https://github.com/openai/tiktoken\n",
        "\n",
        "And costs from: https://openai.com/api/pricing/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0wHR_-JadcQ",
        "outputId": "33556027-fbe5-44dd-dc24-b8d86eb55366",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install tiktoken --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM68g89fadcQ",
        "outputId": "cc113c50-a2cd-486d-9e05-4a4f6fa73cf7"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "\n",
        "def count_tokens(input_string: str) -> int:\n",
        "    encoder = tiktoken.encoding_for_model(\"gpt-4o\")\n",
        "    tokens = encoder.encode(input_string)\n",
        "    return len(tokens)\n",
        "\n",
        "def calculate_cost(input_string: str, cost_per_million_tokens: float = 2.5) -> tuple:\n",
        "    num_tokens = count_tokens(input_string)\n",
        "    total_cost = (num_tokens / 1_000_000) * cost_per_million_tokens\n",
        "    return total_cost, num_tokens\n",
        "\n",
        "def calculate_cost_tokens(num_tokens: int, cost_per_million_tokens: float = 2.5) -> float:\n",
        "    total_cost = (num_tokens / 1_000_000) * cost_per_million_tokens\n",
        "    return total_cost\n",
        "\n",
        "# Example usage:\n",
        "# input_string = \"Porque la gallina cruzó el camino? Pues porque quería llegar al otro lado.\"\n",
        "# cost = calculate_cost(input_string)\n",
        "# print(f\"The total cost for using gpt-4o is: $US {cost:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhoJFRuTadcQ"
      },
      "source": [
        "## Table para ver los resultados\n",
        "\n",
        "Ahora, para ver los resultados de la comparaciones, instalamos un paquete para ver tablas en línea de comandos: https://pypi.org/project/prettytable/\n",
        "\n",
        "Y también instalamos un paquete para ver una barra de progreso bonita en loops: https://pypi.org/project/tqdm/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sxfK7Z1adcQ",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install prettytable --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Q1iG482adcQ",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install tqdm --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMLlOBowadcQ"
      },
      "outputs": [],
      "source": [
        "from typing import List, Callable, Dict\n",
        "from prettytable import PrettyTable\n",
        "from tqdm import tqdm\n",
        "\n",
        "def view_scraped_content(scrape_url_functions: List[Dict[str, Callable[[str], str]]], sites_list: List[Dict[str, str]], characters_to_display: int = 500, table_max_width: int = 50, to_markdown: bool=False) -> List[Dict[str, str]]:\n",
        "    content_table_headers = [\"Site Name\"] + [f\"{func['name']} content\" for func in scrape_url_functions]\n",
        "    cost_table_headers = [\"Site Name\"] + [f\"{func['name']} cost\" for func in scrape_url_functions]\n",
        "\n",
        "    content_table = PrettyTable()\n",
        "    content_table.field_names = content_table_headers\n",
        "\n",
        "    cost_table = PrettyTable()\n",
        "    cost_table.field_names = cost_table_headers\n",
        "\n",
        "    scraped_data = []\n",
        "\n",
        "    for site in sites_list:\n",
        "        content_row = [site['name']]\n",
        "        cost_row = [site['name']]\n",
        "        site_data = {\"provider\": site['name'], \"sites\": []}\n",
        "\n",
        "        for scrape_function in scrape_url_functions:\n",
        "            function_name = scrape_function['name']\n",
        "            for _ in tqdm([site], desc=f\"Processing site {site['name']} using {function_name}\"):\n",
        "                content = scrape_function['function'](site['url'], to_markdown)\n",
        "                content_snippet = content[:characters_to_display]\n",
        "                content_snippet = f\"{len(content):,} characters retrieved:\\n\\n\" + content_snippet\n",
        "                content_row.append(content_snippet)\n",
        "\n",
        "                cost, count_tokens = calculate_cost(content)\n",
        "                cost_row.append(f\"${cost:.6f} (tokens: {count_tokens:,})\")\n",
        "\n",
        "                site_data[\"sites\"].append({\"name\": function_name, \"content\": content})\n",
        "\n",
        "        content_table.add_row(content_row)\n",
        "        cost_table.add_row(cost_row)\n",
        "        scraped_data.append(site_data)\n",
        "\n",
        "    content_table.max_width = table_max_width\n",
        "    content_table.hrules = True\n",
        "\n",
        "    cost_table.max_width = table_max_width\n",
        "    cost_table.hrules = True\n",
        "\n",
        "    print(\"Content Table:\")\n",
        "    print(content_table)\n",
        "\n",
        "    print(\"\\nCost Table:\\nThis is how much it would cost to use gpt-4o to use this content as input.\")\n",
        "    print(cost_table)\n",
        "\n",
        "    return scraped_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVbRcFl0adcR"
      },
      "source": [
        "## Setup all the scrapers\n",
        "\n",
        "Let's setup all of our scrapers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkwGupuBadcR"
      },
      "source": [
        "## Beautiful Soup\n",
        "\n",
        "Se instala este paquete desde: https://pypi.org/project/beautifulsoup4/\n",
        "\n",
        "Y también request para hacer peticiones desde: https://pypi.org/project/requests/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoEo87IUadcR",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install requests beautifulsoup4 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install markdownify --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mh7qfdladcR"
      },
      "outputs": [],
      "source": [
        "# Beautiful Soup utility functions\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from markdownify import markdownify as md\n",
        "\n",
        "def beautiful_soup_scrape_url(url: str, to_markdown: bool = False) -> str:\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    if to_markdown:\n",
        "        return md(str(soup)) # Convert to markdown\n",
        "    return str(soup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6UUmzTSadcR"
      },
      "source": [
        "## Playwright\n",
        "\n",
        "La manera clásica de hacer scraping. No es especial para LLMs desde: https://playwright.dev/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWtcOGvTadcR",
        "outputId": "a651572a-e03d-44a8-8d8b-64d729793d3b",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install playwright --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbL8G798adcR",
        "outputId": "c99e2110-2b90-4dc6-e892-d56a7c6b3c36",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!playwright install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWC6t2UhadcR",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install nest_asyncio --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install markdownify --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-JCvLiFadcR"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import asyncio\n",
        "from playwright.async_api import async_playwright\n",
        "\n",
        "async def scrape_playwright(url: str, to_markdown: bool = False) -> str:\n",
        "    async with async_playwright() as pw:\n",
        "        browser =  await pw.chromium.launch(headless=True)\n",
        "        page = await browser.new_page()\n",
        "        await page.goto(url)\n",
        "        # Espera para que cargue la pagina\n",
        "        await page.wait_for_load_state('domcontentloaded')\n",
        "        # Ejecuta un script para bajar hasta el final de la pagina\n",
        "        # await page.evaluate('window.scrollTo(0, document.body.scrollHeight)')\n",
        "        # Tambien se puede hacer con el teclado\n",
        "        await page.keyboard.press('End')\n",
        "        # Espera a que baje el scroll\n",
        "        await page.wait_for_timeout(2000)\n",
        "\n",
        "        html = await page.content()\n",
        "        if to_markdown:\n",
        "            html = md(html) # Convert to markdown\n",
        "        \n",
        "        await browser.close()\n",
        "        return html\n",
        "\n",
        "def scrape_playwright_sync(url: str, to_markdown: bool = False):\n",
        "    return asyncio.run(scrape_playwright(url, to_markdown))\n",
        "\n",
        "# print(scrape_playwright_sync(\"https://www.amazon.com\", to_markdown=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYsfgXbOadcR"
      },
      "source": [
        "## Reader API by Jina AI\n",
        "\n",
        "Este es especialmente para LLMs también. Setup Jina AI's scrape method from: https://jina.ai/reader/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEHapbAOadcR"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def scrape_jina_ai(url: str, to_markdown: bool = False) -> str:\n",
        "    headers = {\n",
        "        'X-Return-Format': 'markdown' if to_markdown else 'html',\n",
        "        'X-Engine': 'browser',\n",
        "        'X-Timeout': '30',\n",
        "        \"X-With-Images-Summary\": \"none\" if to_markdown else \"all\",\n",
        "    }\n",
        "    data = {\n",
        "        'url': url,\n",
        "        'injectPageScript': [\n",
        "            'document.addEventListener(\"mutationIdle\", window.simulateScroll);'\n",
        "        ]\n",
        "    }\n",
        "    response = requests.post('https://r.jina.ai/', headers=headers, json=data)\n",
        "    return response.text\n",
        "\n",
        "# print(scrape_jina_ai(\"https://www.uv.mx\", to_markdown = True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMtJpLtPadcR"
      },
      "source": [
        "## Crawl4AI: Open-Source LLM-Friendly Web Crawler & Scraper\n",
        "\n",
        "Este es especialmente para obtener formato amigable para LLMs desde: https://docs.crawl4ai.com/\n",
        "\n",
        "Primero instalamos prerequisitos que requiere Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MHc1ZotejiY",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install h5py --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install typing-extensions --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install wheel --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MtRxpOrfevX"
      },
      "source": [
        "Posteriormente, ya podemos realizar la instalación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dc6Gou8-adcR",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install crawl4ai --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_l1aG_radcR",
        "outputId": "5023fad8-6775-44b3-f970-0956828e3ac1",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!crawl4ai-setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPX1z3jqadcR",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install nest_asyncio --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNULITSAadcR"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import asyncio\n",
        "from crawl4ai import AsyncWebCrawler\n",
        "from crawl4ai.async_configs import BrowserConfig, CrawlerRunConfig\n",
        "\n",
        "browser_conf = BrowserConfig(verbose=False,headless=True)\n",
        "\n",
        "run_cfg = CrawlerRunConfig(\n",
        "    wait_until=\"domcontentloaded\",\n",
        "    wait_for_images=True,\n",
        "    scan_full_page=True,\n",
        "    verbose=False,\n",
        ")\n",
        "\n",
        "async def async_scrape_crawl4ai(url: str, to_markdown: bool = False) -> str:\n",
        "    crawler = AsyncWebCrawler(config=browser_conf)\n",
        "    await crawler.start()\n",
        "    result = await crawler.arun(\n",
        "        url=url,\n",
        "        config=run_cfg,\n",
        "    )\n",
        "\n",
        "    if not to_markdown:\n",
        "        return result.html\n",
        "    \n",
        "    # Convert HTML to Markdown\n",
        "    # Get all the images\n",
        "    images = result.media.get(\"images\", [])\n",
        "    images_list = f\"\\n\\nImages found:{len(images)}\"\n",
        "    for i, img in enumerate(images):\n",
        "        images_list = images_list + f\"\\n - ![Image {i+1}: {img.get('alt','No description')}]({img.get('src','')})\"\n",
        "        # Example: - ![Image 1: Alt text](https://example.com/image1.jpg)\n",
        "    \n",
        "    return result.markdown + images_list\n",
        "\n",
        "# To run the async function in a synchronous context\n",
        "# (like this script), you can use asyncio.run() to execute it.\n",
        "# This is a workaround for running async functions in a sync context.\n",
        "def scrape_crawl4ai(url: str, to_markdown: bool = False):\n",
        "    return asyncio.run(async_scrape_crawl4ai(url, to_markdown))\n",
        "\n",
        "# print(scrape_crawl4ai(\"https://www.uv.mx\", to_markdown=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Firecrawl: Turn websites into LLM-ready data\n",
        "\n",
        "Esta es otra opción que no se usará porque tiene costo. También esta enfocado en AI. Desde: https://www.firecrawl.dev/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install firecrawl-py --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "from firecrawl import FirecrawlApp\n",
        "\n",
        "def scrape_firecrawl(url: str, to_markdown: bool = False) -> str:\n",
        "    FIRECRAWL_API_KEY = getpass.getpass('Enter your FireCrawl API key: ')\n",
        "    app = FirecrawlApp(api_key=FIRECRAWL_API_KEY)\n",
        "\n",
        "    # Crawl a website:\n",
        "    scrape_result = app.scrape_url(\n",
        "        url, \n",
        "        params={\n",
        "            'formats': ['html' if not to_markdown else 'markdown'],\n",
        "            'waitFor': 2000,\n",
        "            'actions': [\n",
        "                {\"type\": \"executeJavascript\", \"script\": \"window.scrollTo(0, document.body.scrollHeight)\"},\n",
        "                {\"type\": \"wait\", \"milliseconds\": 2000},\n",
        "            ]   \n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Get the content\n",
        "    if not to_markdown:\n",
        "        return scrape_result['html']\n",
        "    else:\n",
        "        return scrape_result['markdown']\n",
        "    \n",
        "# print(scrape_firecrawl(\"https://www.uv.mx\", to_markdown=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su7fsLEwadcR"
      },
      "source": [
        "## Main functions to run the comparasion with HTML\n",
        "\n",
        "Let's run all the scrapers and display them in our comparison table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzPk7M7oadcR",
        "outputId": "db1e6eb3-348c-4ae0-d9b8-e9ea4a287d5c"
      },
      "outputs": [],
      "source": [
        "list_of_scraper_functions = [\n",
        "      {\"name\": \"Beautiful Soup\", \"function\": beautiful_soup_scrape_url},\n",
        "      {\"name\": \"Jina AI\", \"function\": scrape_jina_ai},\n",
        "      {\"name\": \"Playwright\", \"function\": scrape_playwright_sync},\n",
        "      {\"name\": \"Crawl4ai\", \"function\": scrape_crawl4ai},\n",
        "      ]\n",
        "\n",
        "all_content_html = view_scraped_content(list_of_scraper_functions, test_sites, 800, 35, to_markdown=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Realizamos la comparación con markdown\n",
        "\n",
        "Vamos a ejecutar todos los scrapers pero ahora que devuelvan un formato más amigable para la IA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_content_md = view_scraped_content(list_of_scraper_functions, test_sites, 1200, 35, to_markdown=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conectar con los LLMs para evaluar si puede crear una página web accesible\n",
        "\n",
        "Vamos a enviar el contenido en HTML y en markdown y le vamos a pedir que nos devuelva una sección accesible WCAG 2.2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install openai --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "from openai import OpenAI\n",
        "\n",
        "def extract(model: str, user_input: str, user_prompt: str, template: str = None) -> str:\n",
        "    if model == \"gpt-4o\":\n",
        "        OPENAI_API_KEY = getpass.getpass('Enter your OpenAI API key for gpt-4o: ')\n",
        "        client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "    elif model == \"gemini-2.0-flash\":\n",
        "        GOOGLE_API_KEY = getpass.getpass('Enter your Google API key for gemini-2.0-flash: ')\n",
        "        client = OpenAI(api_key=GOOGLE_API_KEY, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
        "\n",
        "\n",
        "    entity_extraction_system_message = {\n",
        "        \"role\": \"system\", \n",
        "        \"content\": \"\"\"\"\n",
        "        1. You are a helpful assistant expert on web accessibility WCAG that evaluate and correct HTML code.\n",
        "        2. You will be given code and you will analize it.\n",
        "        3. Then, you will create a new webpage from that code but accessible according to WCAG https://www.w3.org/WAI/WCAG22/Understanding/\n",
        "        4. Check all rules including color contrast, alt text, and semantic HTML.\n",
        "        5. Use absolute URLs for the images that have a relative ones.\n",
        "        6. If you include an style.css file, you will add the rules inline in the head section.\n",
        "        7. Also, you will provide a list of the procedure you did respect to the original in markdown format.\n",
        "        8. Dont scape the HTML code, just return it as a string. For example don't add \"\\n\" or \\\" to the HTML code.\n",
        "        9. Return the result as a JSON with values: {Procedure: str, HTML: str}\n",
        "        \"\"\"\n",
        "    }\n",
        "    # Add the system message to the messages list\n",
        "    messages = [entity_extraction_system_message]\n",
        "    # Add the content to the messages list\n",
        "    messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
        "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "    if template:\n",
        "        messages.append({\"role\": \"user\", \"content\": \"The following is a template as a base for the HTML code you will generate with the content. Use bootstrap classes to make it responsive and accessible. \" + template})\n",
        "        messages.append({\"role\": \"user\", \"content\": template})\n",
        "    # Call the OpenAI API to get the response\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        temperature=0.1,\n",
        "        stream=False,\n",
        "        messages=messages,\n",
        "        response_format={\"type\": \"json_object\"},\n",
        "    )\n",
        "    \n",
        "    # return response.choices[0].message.content\n",
        "    return response.choices[0].message.content, response.usage.completion_tokens, response.usage.prompt_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Función que permite comparar los resultados\n",
        "\n",
        "Ahora se crearemos una función para crear una tabla con los resultados de comparar el resultado devuelto en HTML y en Markdown. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def display_extracted_content(model: str, results_html: List[Dict[str, any]], results_md: List[Dict[str, any]], function_name: str, site_name: str):\n",
        "    table = PrettyTable()\n",
        "    table.field_names = [\"Site\", \"From HTML\", \"From markdown\", \"From markdown with template\"]\n",
        "\n",
        "    with open('templates/tem001.html', 'r') as file:  # r to open file in READ mode\n",
        "        html_as_string = file.read()\n",
        "\n",
        "    # Iterate through each site and its content\n",
        "    for i,result in tqdm(enumerate(results_html), desc=\"Processing results\"):\n",
        "        sites_html = results_html[i][\"sites\"]\n",
        "        sites_md = results_md[i][\"sites\"]\n",
        "        provider = results_html[i][\"provider\"]\n",
        "\n",
        "        # Check if the provider matches the site name\n",
        "        if provider == site_name:\n",
        "            for i in range(len(sites_html)):\n",
        "                # Check if the function name matches\n",
        "                if sites_html[i][\"name\"] == function_name:\n",
        "                    # Extract the content for HTML and Markdown\n",
        "                    content_html = sites_html[i][\"content\"]\n",
        "                    content_md = sites_md[i][\"content\"]\n",
        "\n",
        "                    # Progress bar for each function\n",
        "                    for _ in tqdm(range(1), desc=f\"Extracting content with {function_name} for HTML input\"):\n",
        "                        extracted_content_html, completion_tokens, prompt_tokens = extract(model, content_html, \"Use the following HTML code and create a new accessible web page version mantaining all the contents. The absolute URL is https://sistemasfei.uv.mx/inicio/\")\n",
        "                        cost = calculate_cost_tokens(completion_tokens + prompt_tokens)\n",
        "                        cost_label = f\"Completion tokens: {completion_tokens:,}\\nPrompt tokens: {prompt_tokens:,}\\nTotal cost:${cost:.6f}\" + \"\\n\\n\\n\"\n",
        "                        col_content_html = cost_label + extracted_content_html\n",
        "\n",
        "                    # Progress bar for each function\n",
        "                    for _ in tqdm(range(1), desc=f\"Extracting content with {function_name} for Markdown input\"):\n",
        "                        extracted_content_md, completion_tokens, prompt_tokens = extract(model, content_md, \"Use the following content to create a new accessible web page version. Use the code from https://webaim.org/ as a base to create a new accessible web page version. Observe the structure of the header, the images are in on row with the title; also the use of cols and rows to make it responsive and accessible.\", template=None)\n",
        "                        cost = calculate_cost_tokens(completion_tokens + prompt_tokens)\n",
        "                        cost_label = f\"Completion tokens: {completion_tokens:,}\\nPrompt tokens: {prompt_tokens:,}\\nTotal cost:${cost:.6f}\" + \"\\n\\n\\n\"\n",
        "                        col_content_md = cost_label + extracted_content_md\n",
        "\n",
        "                    # Progress bar for each function\n",
        "                    for _ in tqdm(range(1), desc=f\"Extracting content with {function_name} for Markdown input and template\"):\n",
        "                        extracted_content_md_template, completion_tokens, prompt_tokens = extract(model, content_md, \"Use the following content to create a new accessible web page version.\",html_as_string.replace(\"\\n\",\"\"))\n",
        "                        cost = calculate_cost_tokens(completion_tokens + prompt_tokens)\n",
        "                        cost_label = f\"Completion tokens: {completion_tokens:,}\\nPrompt tokens: {prompt_tokens:,}\\nTotal cost:${cost:.6f}\" + \"\\n\\n\\n\"\n",
        "                        col_content_md_template = cost_label + extracted_content_md_template\n",
        "\n",
        "                    table.add_row([provider, col_content_html, col_content_md, col_content_md_template])\n",
        "\n",
        "    table.max_width = 50  # Set the maximum width for better display\n",
        "    table.hrules = True  # Add horizontal rules for better readability\n",
        "\n",
        "    print(\"Extracted Content Table:\")\n",
        "    print(table)\n",
        "\n",
        "    return json.loads(extracted_content_html), json.loads(extracted_content_md), json.loads(extracted_content_md_template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## OpenAI\n",
        "\n",
        "Revisemos el resultado que produce este modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "extracted_json_html, extracted_json_md, extracted_json_md_template = display_extracted_content(\"gpt-4o\", all_content_html, all_content_md, \"Crawl4ai\", \"Sistemas FEI\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizar los resultados obtenidos\n",
        "\n",
        "Instalamos las dependencias necesarias para generar la interface web."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "pip install ipywidgets --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install aiofiles --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install gradio --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creamos una función de apoyo para crear la interface web y poder ver los resultados visualmente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import json\n",
        "import gradio as gr\n",
        "\n",
        "def create_interface():\n",
        "    # Load the JSON data\n",
        "    # json_data_html = json.loads(extracted_json_html)\n",
        "    # json_data_md = json.loads(extracted_json_md)\n",
        "    # json_data_md_template = json.loads(extracted_json_md_template)\n",
        "\n",
        "    with gr.Blocks(theme=gr.themes.Default()) as demo:\n",
        "        # From HTML\n",
        "        with gr.Tab(\"Proc HTML\"):\n",
        "            gr.Markdown(extracted_json_html[\"Procedure\"], label=\"Procedure\")\n",
        "        with gr.Tab(\"Code HTML\"):\n",
        "            gr.TextArea(extracted_json_html[\"HTML\"], label=\"HTML code\", show_copy_button=True, lines=20)\n",
        "        with gr.Tab(\"Res HTML\"):\n",
        "            gr.HTML(extracted_json_html[\"HTML\"])\n",
        "        # From Markdown\n",
        "        with gr.Tab(\"Proc MD\"):\n",
        "            gr.Markdown(extracted_json_md[\"Procedure\"], label=\"Procedure\")\n",
        "        with gr.Tab(\"Code MD\"):\n",
        "            gr.TextArea(extracted_json_md[\"HTML\"], label=\"HTML code\", show_copy_button=True, lines=20)\n",
        "        with gr.Tab(\"Res MD\"):\n",
        "            gr.HTML(extracted_json_md[\"HTML\"])\n",
        "        # From Markdown with template\n",
        "        with gr.Tab(\"Proc MD with template\"):\n",
        "            gr.Markdown(extracted_json_md_template[\"Procedure\"], label=\"Procedure\")\n",
        "        with gr.Tab(\"Code MD with template\"):\n",
        "            gr.TextArea(extracted_json_md_template[\"HTML\"], label=\"HTML code\", show_copy_button=True, lines=20)\n",
        "        with gr.Tab(\"Res MD with template\"):\n",
        "            gr.HTML(extracted_json_md_template[\"HTML\"])\n",
        "\n",
        "    demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "create_interface()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Google Gemini\n",
        "\n",
        "Revisemos el resultado que produce este modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "extracted_json_html, extracted_json_md, extracted_json_md_template = display_extracted_content(\"gemini-2.0-flash\", all_content_html, all_content_md, \"Crawl4ai\", \"Sistemas FEI\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizar los resultados obtenidos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "create_interface()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# if not os.path.exists(\"output\"):\n",
        "#     os.makedirs(\"output\")\n",
        "\n",
        "# with open(f'output/from_html.html', \"w+\", encoding=\"utf-8\") as f:\n",
        "#     f.write(json_data_html[\"HTML\"])\n",
        "\n",
        "# with open(f'output/from_markdown.html', \"w+\", encoding=\"utf-8\") as f:\n",
        "#     f.write(json_data_md[\"HTML\"])\n",
        "\n",
        "# with open(f'output/from_markdown_template.html', \"w+\", encoding=\"utf-8\") as f:\n",
        "#     f.write(json_data_md_template[\"HTML\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install flask --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from flask import Flask\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/html')\n",
        "def index_html():\n",
        "    return json_data_html[\"HTML\"]\n",
        "\n",
        "@app.route('/md')\n",
        "def index_mc():\n",
        "    return json_data_md[\"HTML\"]\n",
        "\n",
        "@app.route('/template')\n",
        "def index_template():\n",
        "    return json_data_md_template[\"HTML\"]\n",
        "\n",
        "app.run(port=5000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "html"
        }
      },
      "source": [
        "From HTML: http://127.0.0.1:5000/html\n",
        "\n",
        "From Markdown: http://127.0.0.1:5000/md\n",
        "\n",
        "From Template: http://127.0.0.1:5000/template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Retrieval-Augmented Generation (RAG)\n",
        "\n",
        "<center><img src=\"images/rag.gif\" style=\"margin:auto; width:50%\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Agentic Retrieval-Augmented Generation (RAG)\n",
        "\n",
        "<center><img src=\"images/arag.gif\" style=\"margin:auto; width:50%\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Chunking strategies\n",
        "\n",
        "<center><img src=\"images/chunks.gif\" style=\"margin:auto; width:50%\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluación de los resultados\n",
        "\n",
        "Recuperamos los resultados de la generación automática para no estar llamando a los modelos en cada prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read the output files\n",
        "def read_output_files(prefix: str):\n",
        "    generated_html = {}\n",
        "    \n",
        "    # Read the HTML content to files\n",
        "    with open(f'output/{prefix}-from_html.html', 'r') as f:\n",
        "        generated_html[\"HTML\"] = f.read()\n",
        "\n",
        "    with open(f'output/{prefix}-from_markdown.html', 'r') as f:\n",
        "        generated_html[\"MD\"] = f.read()\n",
        "\n",
        "    with open(f'output/{prefix}-from_markdown_template.html', 'r') as f:\n",
        "        generated_html[\"TEMPLATE\"] = f.read()\n",
        "    \n",
        "    return generated_html\n",
        "\n",
        "# Read the original HTML file\n",
        "with open(f'output/Crawl4ai-original.html', 'r') as f:\n",
        "    original_html = f.read()\n",
        "\n",
        "# Read the output files\n",
        "generated_html_gpt = read_output_files(\"gpt-4o\")\n",
        "generated_html_gemini = read_output_files(\"gemini-2.0-flash\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
