{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gverafei/scraping/blob/main/scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3flX_YcJTu05"
      },
      "source": [
        "# **Investigating how to scrape the web**\n",
        "March 2025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctzFiDtTTu07"
      },
      "source": [
        "## Configure virtual environment\n",
        "\n",
        "Solo se ejecuta lo siguiente la primera vez. Pedirá seleccionar the kernel from the upper right corner. Choose this virtual environment we just created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!python3 -m venv .venv                                             \n",
        "!source .venv/bin/activate # Linux/Mac\n",
        "# !.\\venv\\Scripts\\activate # Windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in ./.venv/lib/python3.13/site-packages (25.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To hacer el commit de los cambios realizados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized empty Git repository in /Users/gvera/Library/CloudStorage/OneDrive-UniversidadVeracruzana/FEI/codigo/doctorado/scraping/.git/\n"
          ]
        }
      ],
      "source": [
        "!git init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[main (root-commit) bfe1d07] Initial commit\n",
            " 1 file changed, 669 insertions(+)\n",
            " create mode 100644 scraping.ipynb\n"
          ]
        }
      ],
      "source": [
        "!git add scraping.ipynb\n",
        "!git commit -m \"Initial commit\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!git fetch origin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!git add ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[main f4c0fad] Initial commit\n",
            " 2 files changed, 201 insertions(+), 2 deletions(-)\n",
            " create mode 100644 .gitignore\n"
          ]
        }
      ],
      "source": [
        "!git commit -m \"Initial commit\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: refusing to merge unrelated histories\n"
          ]
        }
      ],
      "source": [
        "!git merge origin/main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "# !git remote add origin https://github.com/gverafei/scraping.git\n",
        "# !git pull origin main\n",
        "!git push -u origin main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!git config pull.rebase false"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install required packages\n",
        "\n",
        "```bash\n",
        "pip install html2text\n",
        "pip install markdownify\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the initial data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vo40HI4tnIBm",
        "outputId": "8004fdff-cd55-4cc1-bef0-301a541988e4"
      },
      "outputs": [],
      "source": [
        "competitor_sites = [\n",
        "    # {\n",
        "    #     \"name\": \"Google\",\n",
        "    #     \"url\": \"https://www.google.com\"\n",
        "    # },\n",
        "    {\n",
        "        \"name\": \"UV\",\n",
        "        \"url\": \"https://www.uv.mx\"\n",
        "    },\n",
        "    # {\n",
        "    #     \"name\": \"Amazon\",\n",
        "    #     \"url\": \"https://www.amazon.com\"\n",
        "    # },\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup cost's calculations\n",
        "\n",
        "The idea is to compare side-by-side. \n",
        "\n",
        "We can calculate how much it'll cost by using OpenAI's `tiktoken` library from: https://github.com/openai/tiktoken\n",
        "\n",
        "And costs from: https://openai.com/api/pricing/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install tiktoken --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The total cost for using gpt-4o is: $US 0.000043\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "def count_tokens(input_string: str) -> int:\n",
        "    encoder = tiktoken.encoding_for_model(\"gpt-4o\")\n",
        "    tokens = encoder.encode(input_string)\n",
        "    return len(tokens)\n",
        "\n",
        "def calculate_cost(input_string: str, cost_per_million_tokens: float = 2.5) -> float:\n",
        "    num_tokens = count_tokens(input_string)\n",
        "    total_cost = (num_tokens / 1_000_000) * cost_per_million_tokens\n",
        "    return total_cost\n",
        "\n",
        "# Example usage:\n",
        "input_string = \"Porque la gallina cruzó el camino? Pues porque quería llegar al otro lado.\"\n",
        "cost = calculate_cost(input_string)\n",
        "print(f\"The total cost for using gpt-4o is: $US {cost:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table para ver los resultados\n",
        "\n",
        "Ahora, para ver los resultados de la comparaciones, instalamos un paquete para ver tablas en línea de comandos: https://pypi.org/project/prettytable/\n",
        "\n",
        "Y también instalamos un paquete para ver una barra de progreso bonita en loops: https://pypi.org/project/tqdm/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install prettytable --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install tqdm --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List, Callable, Dict\n",
        "from prettytable import PrettyTable\n",
        "from tqdm import tqdm\n",
        "\n",
        "def view_scraped_content(scrape_url_functions: List[Dict[str, Callable[[str], str]]], sites_list: List[Dict[str, str]], characters_to_display: int = 500, table_max_width: int = 50) -> List[Dict[str, str]]:\n",
        "    content_table_headers = [\"Site Name\"] + [f\"{func['name']} content\" for func in scrape_url_functions]\n",
        "    cost_table_headers = [\"Site Name\"] + [f\"{func['name']} cost\" for func in scrape_url_functions]\n",
        "\n",
        "    content_table = PrettyTable()\n",
        "    content_table.field_names = content_table_headers\n",
        "\n",
        "    cost_table = PrettyTable()\n",
        "    cost_table.field_names = cost_table_headers\n",
        "\n",
        "    scraped_data = []\n",
        "\n",
        "    for site in sites_list:\n",
        "        content_row = [site['name']]\n",
        "        cost_row = [site['name']]\n",
        "        site_data = {\"provider\": site['name'], \"sites\": []}\n",
        "\n",
        "        for scrape_function in scrape_url_functions:\n",
        "            function_name = scrape_function['name']\n",
        "            for _ in tqdm([site], desc=f\"Processing site {site['name']} using {function_name}\"):\n",
        "                try:    \n",
        "                    content = scrape_function['function'](site['url'])\n",
        "                    content_snippet = content[:characters_to_display]\n",
        "                    content_row.append(content_snippet)\n",
        "\n",
        "                    cost = calculate_cost(content)\n",
        "                    cost_row.append(f\"${cost:.6f}\")\n",
        "\n",
        "                    site_data[\"sites\"].append({\"name\": function_name, \"content\": content})\n",
        "                except Exception as e:\n",
        "                    error_message = f\"Error: {str(e)}\"\n",
        "                    content_row.append(error_message)\n",
        "                    cost_row.append(\"Error\")\n",
        "\n",
        "                    site_data[\"sites\"].append({\"name\": function_name, \"content\": error_message})\n",
        "                    continue\n",
        "\n",
        "        content_table.add_row(content_row)\n",
        "        cost_table.add_row(cost_row)\n",
        "        scraped_data.append(site_data)\n",
        "\n",
        "    content_table.max_width = table_max_width\n",
        "    content_table.hrules = True\n",
        "\n",
        "    cost_table.max_width = table_max_width\n",
        "    cost_table.hrules = True\n",
        "\n",
        "    print(\"Content Table:\")\n",
        "    print(content_table)\n",
        "\n",
        "    print(\"\\nCost Table:\\nThis is how much it would cost to use gpt-4o to parse this content for extraction.\")\n",
        "    print(cost_table)\n",
        "\n",
        "    return scraped_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup all the scrapers\n",
        "\n",
        "Let's setup all of our scrapers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Beautiful Soup\n",
        "\n",
        "Se instala este paquete desde: https://pypi.org/project/beautifulsoup4/\n",
        "\n",
        "Y también request para hacer peticiones desde: https://pypi.org/project/requests/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install requests beautifulsoup4 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Beautiful Soup utility functions\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def beautiful_soup_scrape_url(url: str):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    return str(soup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reader API by Jina AI\n",
        "\n",
        "Este es especialmente para LLMs también. Setup Jina AI's scrape method from: https://jina.ai/reader/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def scrape_jina_ai(url: str) -> str:\n",
        "  headers = {\n",
        "        'X-Return-Format': 'html',\n",
        "        'X-Wait-For-Selector': '.slick-initialized',\n",
        "        'X-With-Images-Summary': 'all'\n",
        "  }\n",
        "  data = {\n",
        "      'url': url,\n",
        "      'injectPageScript': [\n",
        "          'window.scrollTo(0, document.body.scrollHeight)'\n",
        "      ]\n",
        "  }\n",
        "\n",
        "  response = requests.post('https://r.jina.ai/', headers=headers, json=data)\n",
        "  return response.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Playwright\n",
        "\n",
        "La manera clásica de hacer scraping. No es especial para LLMs desde: https://playwright.dev/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install playwright --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!playwright install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install nest_asyncio --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import asyncio\n",
        "from playwright.async_api import async_playwright\n",
        "\n",
        "async def scrape_playwright(url: str):\n",
        "    async with async_playwright() as pw:\n",
        "        browser =  await pw.chromium.launch(headless=True)\n",
        "        page = await browser.new_page()\n",
        "        await page.goto(url)\n",
        "        # Espera 5 segundos para que cargue la pagina\n",
        "        await page.wait_for_timeout(2000)\n",
        "        # await page.waitForLoadState('networkidle')\n",
        "        # Ejecuta un script para bajar hasta el final de la pagina\n",
        "        # await page.evaluate('window.scrollTo(0, document.body.scrollHeight)')\n",
        "        # Tambien se puede hacer con el teclado\n",
        "        #await page.keyboard.press('End')\n",
        "        # Espera 5 segundos\n",
        "        # await page.wait_for_timeout(2000)\n",
        "\n",
        "        html = await page.content()\n",
        "        await browser.close()\n",
        "        \n",
        "        return html\n",
        "    \n",
        "def scrape_playwright_sync(url: str):\n",
        "    return asyncio.run(scrape_playwright(url))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Crawl4AI: Open-Source LLM-Friendly Web Crawler & Scraper\n",
        "\n",
        "Este es especialmente para LLMs desde: https://docs.crawl4ai.com/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install crawl4ai --quiet\n",
        "# !pip install git+https://github.com/unclecode/crawl4ai.git@2025-MAR-ALPHA-1 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INIT].... → Running post-installation setup...\n",
            "[INIT].... → Installing Playwright browsers...\n",
            "[COMPLETE] ● Playwright installation completed successfully.\n",
            "[INIT].... → Starting database initialization...\n",
            "[COMPLETE] ● Database initialization completed successfully.\n",
            "[COMPLETE] ● Post-installation setup completed!\n"
          ]
        }
      ],
      "source": [
        "!crawl4ai-setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install nest_asyncio --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import asyncio\n",
        "from crawl4ai import AsyncWebCrawler\n",
        "from crawl4ai.async_configs import BrowserConfig\n",
        "\n",
        "async def async_scrape_crawl4ai(url: str):\n",
        "    browser_config = BrowserConfig(verbose=False,headless=True)\n",
        "    \n",
        "    # async with AsyncWebCrawler(config=browser_config) as crawler:\n",
        "    crawler = AsyncWebCrawler(config=browser_config)\n",
        "    await crawler.start()\n",
        "    result = await crawler.arun(\n",
        "        url=url\n",
        "    )\n",
        "    return result.html\n",
        "\n",
        "# To run the async function in a synchronous context\n",
        "# (like this script), you can use asyncio.run() to execute it.\n",
        "# This is a workaround for running async functions in a sync context.\n",
        "def scrape_crawl4ai(url: str):\n",
        "    return asyncio.run(async_scrape_crawl4ai(url))\n",
        "\n",
        "# print(scrape_crawl4ai(\"https://www.uv.mx\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main functions to run the comparasion\n",
        "\n",
        "Let's run all the scrapers and display them in our comparison table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'beautiful_soup_scrape_url' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m list_of_scraper_functions = [\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m       {\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mBeautiful Soup\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfunction\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mbeautiful_soup_scrape_url\u001b[49m},\n\u001b[32m      3\u001b[39m       \u001b[38;5;66;03m# {\"name\": \"Jina AI\", \"function\": scrape_jina_ai},\u001b[39;00m\n\u001b[32m      4\u001b[39m       {\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mPlaywright\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfunction\u001b[39m\u001b[33m\"\u001b[39m: scrape_playwright_sync},\n\u001b[32m      5\u001b[39m       {\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mCrawl4ai\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfunction\u001b[39m\u001b[33m\"\u001b[39m: scrape_crawl4ai},\n\u001b[32m      6\u001b[39m       ]\n\u001b[32m      8\u001b[39m all_content = view_scraped_content(list_of_scraper_functions, competitor_sites, \u001b[32m500\u001b[39m, \u001b[32m40\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'beautiful_soup_scrape_url' is not defined"
          ]
        }
      ],
      "source": [
        "list_of_scraper_functions = [\n",
        "      {\"name\": \"Beautiful Soup\", \"function\": beautiful_soup_scrape_url},\n",
        "      # {\"name\": \"Jina AI\", \"function\": scrape_jina_ai},\n",
        "      {\"name\": \"Playwright\", \"function\": scrape_playwright_sync},\n",
        "      {\"name\": \"Crawl4ai\", \"function\": scrape_crawl4ai},\n",
        "      ]\n",
        "\n",
        "all_content = view_scraped_content(list_of_scraper_functions, competitor_sites, 500, 40)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
